# pyproject.toml - LLM Ops Development Environment

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "llm-ops-env"
version = "0.1.0"
description = "LLM Ops development environment with GenAI tools"
readme = "README.md"
requires-python = ">=3.13"
license = { text = "MIT" }

# Core dependencies
dependencies = [
    # FastAPI and async frameworks
    "fastapi >= 0.120.0",
    "uvicorn[standard] >= 0.35.0",
    "aiofiles >= 23.2.0",
    "httpx[http2] >= 0.27.0",
    
    # Database and ORM
    "sqlmodel >= 0.0.15",
    "sqlalchemy >= 2.0.41",
    "alembic >= 1.15.0",
    
    # LLM and AI frameworks
    "langchain >= 0.3.0",
    "langgraph >= 0.2.0",
    "langsmith >= 0.1.0",
    "openai >= 1.50.0",
    "anthropic >= 0.39.0",
    "google-generativeai >= 0.8.0",
    "transformers >= 4.46.0",
    "sentence-transformers >= 3.2.0",
    "llama-index >= 0.11.0",
    "instructor >= 1.6.0",
    "dspy-ai >= 2.5.0",
    "semantic-kernel >= 1.15.0",
    
    # Vector databases
    "chromadb >= 0.5.0",
    "qdrant-client >= 1.12.0",
    "weaviate-client >= 4.9.0",
    
    # Token counting and text processing
    "tiktoken >= 0.8.0",
    
    # API development
    "pydantic >= 2.7.0",
    "python-decouple >= 3.8",
    
    # Testing and evaluation
    "ragas >= 0.2.0",
    "pytest >= 8.0.0",
    "pytest-asyncio >= 0.24.0",
    
    # CLI and console output
    "typer >= 0.15.0",
    "rich >= 13.7.0",
    
    # Monitoring and observability
    "wandb >= 0.18.0",
    "mlflow >= 2.17.0",
    
    # Utilities
    "tenacity >= 9.0.0",
    "redis[hiredis] >= 5.3.0",
    "psycopg2-binary >= 2.9.10",
    "asyncpg >= 0.30.0",
]

[project.optional-dependencies]
# GPU acceleration (only install if CUDA available)
gpu = [
    "torch >= 2.5.0",
    "vllm >= 0.6.0",
    "xformers >= 0.0.28",
    "flash-attn >= 2.7.0",
]

# Development tools
dev = [
    "ruff >= 0.9.0",
    "mypy >= 1.7.0",
    "pre-commit >= 3.0.0",
    "ipython >= 8.0.0",
]

# Interactive tools
interactive = [
    "gradio >= 5.0.0",
    "streamlit >= 1.40.0",
    "jupyter >= 1.1.0",
    "notebook >= 7.3.0",
]

# All optional dependencies
all = [
    "llm-ops-env[gpu,dev,interactive]",
]

[tool.ruff]
line-length = 150
target-version = "py313"

[tool.ruff.lint]
select = [
    "E",     # pycodestyle errors
    "W",     # pycodestyle warnings  
    "F",     # pyflakes
    "I",     # isort
    "B",     # flake8-bugbear
    "A",     # flake8-builtins
    "ASYNC", # flake8-async
]
ignore = [
    "E501",  # Line too long
    "B008",  # Do not perform function calls in argument defaults
]

[tool.ruff.format]
quote-style = "double"
indent-style = "space"

[tool.mypy]
python_version = "3.13"
warn_return_any = true
warn_unused_configs = true
ignore_missing_imports = true 